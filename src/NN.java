/**
 * A neural network
 */
public class NN {
    /**
     * layers
     */
    Layer[] layers;

    /**
     * inputs
     */
    double[] inputs;

    /**
     * outputs (generated by the network)
     */
    double[] outputs;

    /**
     * activation function
     */
    ActivationFunction act = new Sigmoid();

    /**
     * loss function
     */
    LossFunction loss = new MSE();

    /**
     * training rate
     */
    double trainingRate = 0.003;

    /**
     * Dataset to train on (format: {inputs, outputs})
     */
    double[][][] trainset;

    /**
     * Constructor, will create layers based on given layer sizes and randomly
     * initialize layer values
     *
     * @param sizes sizes of the layers
     */
    public NN(int[] sizes) {
        if (sizes.length < 1) {
            throw new IllegalArgumentException("Must have at least 1 layer.");
        }

        layers = new Layer[sizes.length];
        layers[0] = new InputLayer(sizes[0]);
        for (int i = 1; i < sizes.length; i++) {
            layers[i] = new FCLayer(sizes[i], layers[i-1]);
        }

        inputs = layers[0].v;
        outputs = layers[layers.length-1].v;

        randomInit();
    }

    /**
     * Constructor, will create layers based on given layer sizes, randomly
     * initialize layer values, and assign the activation function
     *
     * @param sizes sizes of the layers
     * @param act activation function
     */
    public NN(int[] sizes, ActivationFunction act) {
        this(sizes);

        this.act = act;

        for (Layer layer : layers) {
            layer.act = act;
        }
    }

    /**
     * Randomly initialize the weights and biases of all layers
     */
    public void randomInit() {
        for (Layer layer : layers) {
            layer.init();
        }
    }


    public void addTrainset(double[][] inputs, double[][] outputs) {
        trainset = new double[][][]{inputs, outputs};
    }

    public void prop(double[] inputs) {
        if (inputs.length != layers[0].size) {
            throw new IllegalArgumentException("Input size must match input layer size.");
        }

        layers[0].v = inputs;
        for (int i = 1; i < layers.length; i++) {
            layers[i].prop();
        }
    }

    public double[][][] backprop(double[] outputs) {
        if (outputs.length != this.outputs.length) {
            throw new IllegalArgumentException("Output size must match output layer size.");
        }

        double[][][] deltas = new double[layers.length+1][][];

        double[] db = loss.der(outputs, this.outputs);
        deltas[layers.length] = new double[][]{db};
        for (int i = layers.length-1; i > 0; i--) {
            deltas[i] = layers[i].backprop(db);
            db = deltas[i][deltas[i].length-1];
        }

        return deltas;
    }

    public void train(double[][][] deltas) {
        for (int i = 1; i < layers.length; i++) {
            for (int j = 0; j < layers[i].size; j++) {
                for (int k = 0; k < layers[i].w[j].length; k++) {
                    layers[i].w[j][k] += trainingRate*deltas[i][j][k];
                }
                layers[i].b[j] += trainingRate*deltas[i+1][deltas[i+1].length-1][j];
            }
        }
    }

    public double getLoss(double[] outputs) {
        return loss.func(outputs, this.outputs);
    }

    public double getLoss(double[] inputs, double[] outputs) {
        prop(inputs);
        return getLoss(outputs);
    }

    public double getLoss(double[][] inputs, double[][] outputs) {
        double meanLoss = 0;
        for (int i = 0; i < inputs.length; i++) {
            meanLoss += getLoss(inputs[i], outputs[i]);
        }
//        prop(inputs[0]);
//        System.out.println(Arrays.toString(outputs[0]) + " " + getLoss(outputs[0]));
//        System.out.println(Arrays.toString(inputs[0]) + " " + getLoss(inputs[0], outputs[0]));
//        System.out.println(meanLoss + " " + (meanLoss / inputs.length));
        return meanLoss / inputs.length;
    }

    public double[] trainOn(double[][] inputs, double[][] outputs, int batches) {
        double[] losses = new double[batches];

        int batchSize = (int)Math.ceil((double) inputs.length / batches);
        for (int i = 0, batchIdx = 0; i < batches; i++) {
            double[][][] meanDeltas = new double[layers.length+1][][];
            for (int j = 0; batchIdx < inputs.length && j < batchSize; j++, batchIdx++) {
                prop(inputs[batchIdx]);
                Utils.add(meanDeltas, backprop(outputs[batchIdx]));

            }
            Utils.mult(meanDeltas, 1.0/batchSize);



            train(meanDeltas);
            losses[i] = getLoss(trainset[0], trainset[1]);
        }

        return losses;
    }

    @Override
    public String toString() {
        String s = "";
        for (Layer layer: layers) s += layer.toString() + "\n";
        return s;
    }
}